---
title: "52414 - lab 1"
author: "Noam Malki and Noa schkolnik"
date: "4/4/2020"
output: html_document
---

# *Lab 1: Basic Data Wrangling*  
<br/><br/>  
  

**Contents**:  

* Q0) [Submission Instructions](#submission-instructions)  
* Q1) [Data Preparation and Manipulation](#data-preparation-and-manipulation)      
* Q2) [Analysis of Daily New Corona Cases and Deaths](#analysis-of-daily-new-corona-cases-and-deaths)    
* Q3) [Preparing and Analyzing the World Bank Data](#preparing-and-analyzing-the-world-bank-data)
* Q4) [Joining the Datasets](#joining-the-datasets)  
* Q5) [Open Question](#open-question)

<br/><br/>
  
  
### Submission Instructions  
  
This lab will be submitted in pairs using GitHub (if you don't have a pair, please contact us).  
Please follow the steps in the  [GitHub-Classroom Lab 1](https://classroom.github.com/g/oSZNtHq4) to create your group's Lab 1 repository.  
**Important: your team's name must be `FamilyName1_Name1_and_FamilyName2_Name2`**.  
You can collaborate with your partner using the git environment; You can either make commits straight to master, or create individual branches (recommended). However, once done, be sure to merge your branches to master - you will be graded using the most recent master version - your last push and merge before the deadline.   
**Please do not open/review other peoples' repositories - we will be notified by GitHub if you do.**

Your final push should include this Rmd file (with your answers) together with the html file that is outputted automatically by knitr when you knit the Rmd. Anything else will be disregarded. In addition, please adhere to the following file format:    
`Lab_2_FamilyName1_Name1_and_FamilyName2_Name2.Rmd/html`      


<br/><br/>
  
The only allowed libraries are the following (**please do not add your own**):
```{r, include=FALSE}
library('tidyverse')
library(data.table)
```  
<br/><br/>

## A Deeper Dive Into John's Hopkins Corona Database         
    
The John's Hopkins Novel Corona Virus (COVID-19) epidemiological data is compiled by the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) from various sources. <br>
The dataset contains data since 22nd of January 2020. For the data and more information about it, please visit [here](https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases).    
  
In this lab you will pick up where we left in lecture 2 and analyze the Corona cases and deaths data.  

### Q1
### Data Preparation and Manipulation   
(25 points)  

1. We first prepare and aggregate the data.   

a. First, load the `Corona Confirmed Cases Narrow`, the `Corona Confirmed Deaths Narrow`, and the `Corona Confirmed Recovered Narrow` datasets directly from the John's Hopkins website.  
The type of the `Date` variable should be date type. (2 pts)      
b. Create new data-frames named `cases.agg`, `deaths.agg`, and `recovered.agg` which aggregate the `sum` of Corona cases, deaths, and recovered respectively over the different countries' provinces. To do this, aggregate `Value` using only the country and date features, ignoring all other features (similarly to what has been shown in `lecture 2`).  
To achieve the aggregation use the `aggregate` function. In addition, order the data-frame first by Country and then by Date (increasing order). The columns of each of the two resulting data-frames should be `Country.Region, Date, Value`. (5pts)   
c. Repeat (b) using `tidyverse` and the pipe. Show that the outputs from the two methods are the same. (5pts)  
d. Using the last day of March as a reference, create a single stacked bar-plot that visualizes the top 10 countries in terms of their Corona cases, and their respected Corona deaths and recovered cases stacked on top of the current sick people in three different colors (each stack should add up to total cases). Make sure that the first bar shows the number of confirmed Corona sick people (`sick = cases - deaths - recovered`). What is the biggest issue with the information presented in this plot? (13pts)

   
  
**Solution:**

**Section a:**

```{r}
Sys.setenv(TZ="UTC") # this is essential for the date parsing

confirmed_cases <- read.csv(url("https://data.humdata.org/hxlproxy/data/download/time_series_covid19_confirmed_global_narrow.csv?dest=data_edit&filter01=merge&merge-url01=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D1326629740%26single%3Dtrue%26output%3Dcsv&merge-keys01=%23country%2Bname&merge-tags01=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&filter02=merge&merge-url02=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D398158223%26single%3Dtrue%26output%3Dcsv&merge-keys02=%23adm1%2Bname&merge-tags02=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&merge-replace02=on&merge-overwrite02=on&filter03=explode&explode-header-att03=date&explode-value-att03=value&filter04=rename&rename-oldtag04=%23affected%2Bdate&rename-newtag04=%23date&rename-header04=Date&filter05=rename&rename-oldtag05=%23affected%2Bvalue&rename-newtag05=%23affected%2Binfected%2Bvalue%2Bnum&rename-header05=Value&filter06=clean&clean-date-tags06=%23date&filter07=sort&sort-tags07=%23date&sort-reverse07=on&filter08=sort&sort-tags08=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv"), comment.char = "#")

deaths <- read.csv(url("https://data.humdata.org/hxlproxy/data/download/time_series_covid19_deaths_global_narrow.csv?dest=data_edit&filter01=merge&merge-url01=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D1326629740%26single%3Dtrue%26output%3Dcsv&merge-keys01=%23country%2Bname&merge-tags01=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&filter02=merge&merge-url02=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D398158223%26single%3Dtrue%26output%3Dcsv&merge-keys02=%23adm1%2Bname&merge-tags02=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&merge-replace02=on&merge-overwrite02=on&filter03=explode&explode-header-att03=date&explode-value-att03=value&filter04=rename&rename-oldtag04=%23affected%2Bdate&rename-newtag04=%23date&rename-header04=Date&filter05=rename&rename-oldtag05=%23affected%2Bvalue&rename-newtag05=%23affected%2Binfected%2Bvalue%2Bnum&rename-header05=Value&filter06=clean&clean-date-tags06=%23date&filter07=sort&sort-tags07=%23date&sort-reverse07=on&filter08=sort&sort-tags08=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv"), comment.char = "#")

recovered_cases <- read.csv(url("https://data.humdata.org/hxlproxy/data/download/time_series_covid19_recovered_global_narrow.csv?dest=data_edit&filter01=merge&merge-url01=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D1326629740%26single%3Dtrue%26output%3Dcsv&merge-keys01=%23country%2Bname&merge-tags01=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&filter02=merge&merge-url02=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2Fe%2F2PACX-1vTglKQRXpkKSErDiWG6ycqEth32MY0reMuVGhaslImLjfuLU0EUgyyu2e-3vKDArjqGX7dXEBV8FJ4f%2Fpub%3Fgid%3D398158223%26single%3Dtrue%26output%3Dcsv&merge-keys02=%23adm1%2Bname&merge-tags02=%23country%2Bcode%2C%23region%2Bmain%2Bcode%2C%23region%2Bsub%2Bcode%2C%23region%2Bintermediate%2Bcode&merge-replace02=on&merge-overwrite02=on&filter03=explode&explode-header-att03=date&explode-value-att03=value&filter04=rename&rename-oldtag04=%23affected%2Bdate&rename-newtag04=%23date&rename-header04=Date&filter05=rename&rename-oldtag05=%23affected%2Bvalue&rename-newtag05=%23affected%2Binfected%2Bvalue%2Bnum&rename-header05=Value&filter06=clean&clean-date-tags06=%23date&filter07=sort&sort-tags07=%23date&sort-reverse07=on&filter08=sort&sort-tags08=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_recovered_global.csv"), comment.char = "#")


confirmed_cases$Date <- as.Date(confirmed_cases$Date)
deaths$Date <- as.Date(deaths$Date)
recovered_cases$Date <- as.Date(recovered_cases$Date)

# Checking for Date class
class(confirmed_cases$Date)
class(deaths$Date)
class(recovered_cases$Date)
```

**Section b:**

```{r}
cases_data <- confirmed_cases[c("Country.Region", "Date", "Value")] 
deaths_data <- deaths[c("Country.Region", "Date", "Value")]
recovered_data <- recovered_cases[c("Country.Region", "Date", "Value")]

cases.agg <- aggregate(Value ~ Country.Region + Date, data = cases_data, FUN = sum)
recovered.agg <- aggregate(Value ~ Country.Region + Date, data = recovered_cases, FUN = sum)
deaths.agg <- aggregate(Value ~ Country.Region + Date, data = deaths_data, FUN = sum)
```

**Section c:**

```{r}
cases.tidy_agg <- cases_data %>% group_by(Country.Region, Date) %>% summarise(Cases = sum(Value))
cases.tidy_agg <- arrange(cases.tidy_agg, Date)

recovered.tidy_agg <- recovered_cases %>% group_by(Country.Region, Date) %>% summarise(Recovered = sum(Value)) 
recovered.tidy_agg <- arrange(recovered.tidy_agg, Date)

deaths.tidy_agg <- deaths_data %>% group_by(Country.Region, Date) %>% summarise(Deaths = sum(Value))
deaths.tidy_agg <- arrange(deaths.tidy_agg, Date)

# Checking for similarity
all(deaths.agg == deaths.tidy_agg)
all(cases.agg == cases.tidy_agg)
all(recovered.agg == recovered.tidy_agg)
```

**Section d:**

```{r}
all_data <- full_join(full_join(cases.tidy_agg, deaths.tidy_agg), recovered.tidy_agg)
data_with_sick <- mutate(all_data, Sick = Cases - Deaths - Recovered)
end_march <- data_with_sick[which(data_with_sick$Date == "2020-03-31"), ]
end_march <- end_march[order(end_march$Cases, decreasing = TRUE), ]

march_top_10 <- head(end_march[, !names(end_march) %in% c("Cases", "Date")], 10)
march_top_10 <- march_top_10[, c("Country.Region", "Sick", "Deaths", "Recovered")]

# preparing the data for barplot
data_for_plot <- t(march_top_10)
colnames(data_for_plot) <- march_top_10$Country.Region
data_for_plot <- data_for_plot[-c(1), ]

barplot(data_for_plot, las = 2, col = c("gold", "brown2", "chartreuse3"),
        legend.text = c("Sick", "Deaths", "Recovered"), ylim = c(0, 200000), 
        main = "Top 10 Corona-Infected Countries in 31.3.2020", cex.names = 0.6, cex.axis = 0.8)

```

**The biggest issue with the information presented in this plot is that proportion of the bars can't explain what happens in countries with smaller deaths count or number of recovered people (for example: Turkey, UK, Switzerland and so on).**

<br/><br/>  

### Q2
### Analysis of Daily New Corona Cases and Deaths  
20 points

The two datasets (Corona Cases and Deaths) register the value of cases and deaths, respectively, as a cumulative sum for each day. In this question we would like to understand the daily differences between consecutive days.     

a. Add a new column named `Diff` to both the `cases.agg` and the `deaths.agg` data-frames. This new column should register the daily `Value` difference for each country. In other words, the `Diff` column shows how many new cases/deaths each country incurs every day. Hint - diff must be per country. (7pts)  
b. Find the top 10 instances of country and date combinations with the greatest absolute number of new daily Corona cases and deaths (separately). Print the result in a descriptive format. (5pts)  
c. In one figure, plot Italy's new daily Corona cases AND deaths as a function of Date. Choose the plot type you think that makes the most sense. (3pts) 
d. Plot the same graph as in (c), but this time plot the number of new cases on the logarithm scale. What can we learn? (5pts)  

  
**Solution:**

**Section a:**
```{r}
cases.agg <- cases.agg %>% group_by(Country.Region) %>% mutate(Diff = abs(Value - lag(Value, default = Value[1]))) 
deaths.agg <- deaths.agg %>% group_by(Country.Region) %>% mutate(Diff = abs(Value - lag(Value, default = Value[1]))) 
```

**Section b:**
```{r}
top_cases_diff <- head(cases.agg[order(cases.agg$Diff, decreasing = TRUE), ], 10)
top_deaths_diff <- head(deaths.agg[order(deaths.agg$Diff, decreasing = TRUE), ], 10)

top_cases_diff
top_deaths_diff
```

**Section c:**
```{r}
italy_cases <- cases.agg[which(cases.agg$Country.Region == 'Italy'), ]
italy_deaths <- deaths.agg[which(deaths.agg$Country.Region == 'Italy'), ]

plot(italy_cases$Date, italy_cases$Diff, col = "blue",
     xlab = "Date", ylab = "Count", main = "New daily Corona cases and deaths in Italy")
points(italy_cases$Date, italy_deaths$Diff, col = "red")
legend("topleft", legend = c("cases", "Deaths"), col = c("blue", "red"), pch = 1:1)
```

**Section d:**
```{r}
plot(italy_cases$Date, log(italy_cases$Diff), col = "blue",
     xlab = "Date", ylab = "Count in logarithm scale", main = "New daily Corona cases and deaths in Italy")
points(italy_cases$Date, log(italy_deaths$Diff), col = "red")
legend("topleft", legend = c("cases", "Deaths"), col = c("blue", "red"), pch = 1:1)
```


**We can learn that there was an exponential growth rate in the number of cases and deaths, but it stopped being exponential near the end of March.**

<br/><br/>


### Q3
### Preparing and Analyzing the World Bank Data   
25 points

a. Rename the columns of `eco_data`: `country,S_country,feature,feature_code,Y2018V,Y2019V`. (2pts)  
b. Create a new `eco` data-frame whose dimensions are $266 \times 11$. The first column should include the names of the countries in `eco_data.`   
The rest of the columns should be the features with their respective values in `eco_data` for each country from 2018. Print the head of the new data-frame.(8pts)  
c. Select and rename the following columns: `country` as country, `GDP(US currency)` as GDP, `Population ages 65 and above (% of total population)` as pop65, `Population in the largest city (% of urban population)` as pop_city_ratio, `Population, total` as pop_total columns .  (2pts) 
d. Show a table of the five countries with the highest per capita GDP in 2018.     
Next (considering all countries), plot the % of population over 65 vs. log of GDP per capita in 2018, after excluding the 10% countries with the lowest GDP per capita. Using `lm` and `abline`, add a regression line to the plot. What is your conclusion? (13 pts)  
  
  
  
**Solution:** 

**Section a:**

```{r}
#loading the `eco_data`:
eco_data <- read.csv(url("https://raw.githubusercontent.com/DataScienceHU/DataAnalysisR_2020/master/data/economic_data.csv"))

colnames(eco_data) <- c('country' ,'S_country', 'feature', 'feature_code', 'Y2018V', 'Y2019V')
```

**Section b:**
```{r}
eco_data <- eco_data[1:2640,]
eco <- dcast(eco_data, country~feature, value.var='Y2018V')
```

**Section c:**
```{r}
colnames(eco)[colnames(eco) == 'country'] <- 'country'
colnames(eco)[colnames(eco) == 'Population ages 65 and above (% of total population)'] <- 'pop65'
colnames(eco)[colnames(eco) == 'Population in the largest city (% of urban population)'] <- 'pop_city_ratio'
colnames(eco)[colnames(eco) == 'Population, total'] <- 'pop_total'
```

**Section d:**
```{r}
eco_GDP <- eco
eco_GDP[eco_GDP == ".."] <- 0
colnames(eco_GDP)[colnames(eco_GDP) == 'GDP (current US$)'] <- 'GDP'
eco_GDP <- mutate(eco_GDP, capita_GDP = as.numeric(GDP)/ as.numeric(pop_total))
eco_GDP <- eco_GDP[order(eco_GDP$capita_GDP, decreasing = TRUE), ][1:238,]  # order in decreasing odrer the countries by capita_GDP without the lowest 10% (264*0.9=237.6)
plot(x=log(eco_GDP$capita_GDP), y=eco_GDP$pop65, xlab = 'capita GDP', ylab = 'pop65', col='blue', main="capita_GDP and populathion above 65 in 2018" )
abline(lm(pop65 ~ log(capita_GDP), data =  eco_GDP))
```

**We can conclude that there is a positive conection between the age of the population and the capita GDP**

<br/><br/>  


### Q4
### Joining the Datasets   
20 points

a. Join the `deaths.agg`, `cases.agg`, and `recovered.agg` into one data-frame called `corona`.(5pts)
b. Join the `corona` and `eco` data-frames in a way that will keep the most information regarding the data (but not full join).   
Make sure that no essential data is thrown away (show this). (3pts)
c. Create new columns of normalized `cases`, `deaths`, and `recovered` so they will show the number of cases per 100,000 people for each country.   
Using the last day of March as a reference, create a single stacked bar plot that visualizes the top 10 countries in terms of normalized Corona cases, and their respected normalized Corona deaths and recovered, as done in Q1.   
how is it different from the graph before normalization? (5pts)
d. Using the last day of March as a reference, create a scatter-plot of normalized deaths and cases vs. `pop65`. Limit the plot to show only countries with 15% or more of `pop65`.   
In addition, color the outliers( pop65>24, norm100K_deaths>15) in that plot in red and add to the plot their country names (7pts)
  
  
**Solution:**   

**Section a:**
```{r}

colnames(cases.agg)[colnames(cases.agg) == 'Value'] <- 'cases'
colnames(recovered.agg)[colnames(recovered.agg) == 'Value'] <- 'recovered'
colnames(deaths.agg)[colnames(deaths.agg) == 'Value'] <- 'deaths'
colnames(cases.agg)[colnames(cases.agg) == 'Diff'] <- 'cases_diff'
colnames(recovered.agg)[colnames(recovered.agg) == 'Diff'] <- 'recovered_diff'
colnames(deaths.agg)[colnames(deaths.agg) == 'Diff'] <- 'deaths_diff'
corona <- full_join(full_join(cases.agg, deaths.agg), recovered.agg)
```

**Section b:**
```{r}
names(corona)[1] <- "country"
corona_eco <-merge(eco,corona)
```

**Section c:**
```{r}
corona_eco <- mutate(corona_eco, 'cases /100,000 pop' = suppressWarnings(as.numeric(cases)/(as.numeric(pop_total)/100000)))
corona_eco <- mutate(corona_eco, 'deaths /100,000 pop' = suppressWarnings(as.numeric(deaths)/(as.numeric(pop_total)/100000)))
corona_eco <- mutate(corona_eco, 'recovered /100,000 pop' = suppressWarnings(as.numeric(recovered)/(as.numeric(pop_total)/100000)))

corona_eco_with_sick <- mutate(corona_eco, Sick = `cases /100,000 pop` - `recovered /100,000 pop` - `deaths /100,000 pop`)

end_march_normalized  <- corona_eco_with_sick[which(corona_eco_with_sick$Date == "2020-03-31"), ]

end_march_normalized <- end_march_normalized[order(as.numeric(end_march_normalized$`cases /100,000 pop`), decreasing = TRUE), ]

march_top_10_normalized <- head(end_march_normalized[, !names(end_march_normalized) == "cases /1m _pop"], 10)

barplot(t(cbind(march_top_10_normalized$Sick,
                march_top_10_normalized$`recovered /100,000 pop`, march_top_10_normalized$`deaths /100,000 pop`)),
        names.arg = march_top_10_normalized$country, las = 2, col = c("gold", "brown2", "chartreuse3"),
        legend.text = c("Sick", "Deaths", "Recovered"), main="MARCH TOP 10 normalized by 100,000", las = 2, ylim = c(0,700),
        cex.names = 0.8, cex.axis = 0.8)
```

**The main difference is that we normalized the data and the size of the population doesn't affect our analysis. For example, a country with 100,000 sick people that have 10,000,000 peopole (1% of population) can sustain better the amount of sick people then a counrty with 100,000 sick people that have 1,000,000 people (10% of the population). We can conclude that the countries with the most cases are not necessarily the most affected countries by the pandemic.**

**Section d:**
```{r}
end_march_normalized_up15 <- end_march_normalized %>% filter(as.numeric(pop65)>= 15)
#create the plot with the special additions as requested by the question
plot(end_march_normalized_up15$pop65,end_march_normalized_up15$`cases /100,000 pop`,
     col =ifelse(end_march_normalized_up15$pop65 > 24,"red","green"), 
     ylab = "normalized deaths and cases",xlab = "% of population over 65",main = "normalized deaths and cases vs. pop65")
points(end_march_normalized_up15$pop65,end_march_normalized_up15$`deaths /100,000 pop`, 
       col = ifelse(end_march_normalized_up15$`deaths /100,000 pop` > 15 | end_march_normalized_up15$pop65 > 24,"red","blue"))
legend("topright",c("norm cases","norm death","pop65 > 24 or norm death > 15"),cex = .8,col = c("green","blue","red"),pch = c(1,1))
text(end_march_normalized_up15$pop65, end_march_normalized_up15$`deaths /100,000 pop`,
     ifelse(end_march_normalized_up15$pop65 >24 | end_march_normalized_up15$`deaths /100,000 pop` > 15,
            as.character(end_march_normalized_up15$country),""), cex=0.65, pos=3,col="red")
```

<br/><br/>  



### Q5
### Open Question
10 points
  
Write an interesting research question regarding the Corona outbreak and then follow the steps to answer it using tables and plots. You can use the loaded datasets or any other dataset you find as long as you add the data file to your `lab1` repository so it can be loaded directly from a `url` (e.g. the World Bank). This question will be graded based on creativity, originality, and the novelty of the analysis.   
  
**Solution:**   

**Our question is "Has life expectancy contributed to the Corona outbreak?"**
**We can break it to two questions:**
**1) Has life expectancy affected to the number of cases of Corona?**
**2) Has life expectancy affected to the number of death caused by Coronavirus?**

**Therefore, we will use a life expectancy's dataset of the Oxford University in the solution** 
[reference](https://ourworldindata.org/life-expectancy)  


```{r}

life_expect_data <- read.csv(url("https://raw.githubusercontent.com/DataScienceHU/52414-lab-1-malki_noam_and_schkolnik_noa/master/life-expectancy.csv"))

# organizing the Data 
life_expect_2019 <- life_expect_data[which(life_expect_data$Year == 2019), ]
areas <- c("Africa", "Americas", "Asia", "Europe", "Latin America and the Caribbean", "Northern America", "Oceania", "World")
life_expect_2019 <- life_expect_2019[, -which(life_expect_2019$Entity %in% areas)]
life_expect_2019 <- life_expect_2019 %>% select(country = Entity, Value_in_years = Life.expectancy..years.)
life_expect_2019$Value_in_years <- round(life_expect_2019$Value_in_years)  

last_date <- max(corona_eco$Date)
recent_data <- corona_eco[which(corona_eco$Date == last_date), ]
recent_cases <- recent_data[c("country", "cases /100,000 pop")]
recent_deaths <- recent_data[c("country", "deaths /100,000 pop")]
recent_cases <- recent_cases[order(recent_cases$`cases /100,000 pop`, decreasing = TRUE), ]
recent_deaths <- recent_deaths[order(recent_deaths$`deaths /100,000 pop`, decreasing = TRUE), ]
cases_with_life_expect <- left_join(recent_cases, life_expect_2019)
deaths_with_life_expect <- left_join(recent_deaths, life_expect_2019)

# we assume that there is an exponential connection
cases_with_life_expect <- mutate(cases_with_life_expect, norm_cases_log = log(`cases /100,000 pop`))
deaths_with_life_expect <- mutate(deaths_with_life_expect, norm_deaths_log = log(`deaths /100,000 pop`))
deaths_with_life_expect <- deaths_with_life_expect[-which(deaths_with_life_expect$norm_deaths_log == -Inf),] # remove minus infinity


par(mfrow=c(1,2))


plot(cases_with_life_expect$Value_in_years, cases_with_life_expect$norm_cases_log,
     ylab = "Cases per 100000 in logarithm scale", xlab = "Life expectancy in years", main = "Cases VS Life expectancy")
abline(lm(cases_with_life_expect$norm_cases_log ~ cases_with_life_expect$Value_in_years), col = "blue") 


plot(deaths_with_life_expect$Value_in_years,deaths_with_life_expect$norm_deaths_log,
     ylab = "deaths per 100000 in logarithm scale", xlab = "Life expectancy in years", main = "Deaths VS Life expectancy")
abline(lm(deaths_with_life_expect$norm_deaths_log ~ deaths_with_life_expect$Value_in_years), col = "red")
```


**It seems that there is an exponential connection between the Corona cases and life expectancy. A similar connection can be seen between life expectancy and deaths caused by Coronavirus. But there is a big scattering in the two plots which means the variances is high. We can assume that there is a connection but it's not strong.**

**Let's make a reggersion model analysis in order to verify our assumption.**

```{r}
regr_deaths <- lm(deaths_with_life_expect$norm_deaths_log ~ deaths_with_life_expect$Value_in_years)
regr_cases <- lm(log(cases_with_life_expect$norm_cases_log) ~ cases_with_life_expect$Value_in_years)
summary(regr_cases)
summary(regr_deaths)
```

**As we can see, the estimators are very good in both models. But the value of R-squared is low in both models which means that life expectancy doesn't explain well the Corona Cases nor deaths. In that case, we can conclude that there is some connection. But there are more facrors which may affect the Corona Cases and deaths (like: opened borders), that we didn't consider.**



<br/><br/>  